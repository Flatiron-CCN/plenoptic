name: build
on:
  workflow_dispatch:
  schedule:
  - cron: 0 0 * * 0     # weekly
  pull_request:
    branches:
    - main

jobs:
  # based on https://slashgear.github.io/how-to-split-test-by-folder-with-github-action/
  get_test_scripts:
    runs-on: ubuntu-latest
    outputs:
      script: ${{ steps.get-scripts.outputs.script }}
    steps:
    - uses: actions/checkout@v3
    - id: get-scripts
        # we cd into tests so that the output of this is just e.g.,
        # "test_tools.py", not "tests/test_tools.py", because we want to run
        # pytest from inside the tests/ dir for coverage to work properly (note
        # this is different than for the notebooks)
      run: "echo \"script=$(cd tests/ && ls test*py | jq -R -s -c 'split(\"\\n\")[:-1]')\"\
        \ >> $GITHUB_OUTPUT\n"
  get_notebooks:
    runs-on: ubuntu-latest
    outputs:
      notebook: ${{ steps.get-notebooks.outputs.nb }}
    steps:
    - uses: actions/checkout@v3
    - id: get-notebooks
      run: "echo \"nb=$(ls examples/*ipynb | jq -R -s -c 'split(\"\\n\")[:-1]')\"\
        \ >> $GITHUB_OUTPUT\n"
  notebooks:
    runs-on: ubuntu-latest
    needs: [get_notebooks]
    strategy:
      matrix:
        python-version: [3.7, 3.8, 3.9, '3.10']
        notebook: ${{fromJson(needs.get_notebooks.outputs.notebook)}}
      fail-fast: false
    name: Execute notebooks
    steps:
    - uses: actions/checkout@v3
    - uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: pip
        cache-dependency-path: setup.py
    - name: Setup FFmpeg
      uses: FedericoCarboni/setup-ffmpeg@v2
    - name: Install dependencies
      # nbclient 0.5.5 is the first version that includes jupyter execute
      run: |
        pip install --upgrade --upgrade-strategy eager .
        pip install jupyter ipywidgets
        pip install "nbclient>=0.5.5"
    - name: Download TID2013 dataset
      if: ${{ matrix.notebook == 'examples/04_Perceptual_distance.ipynb' }}
      run: |
        mkdir -p data
        wget https://osf.io/7nfkz/download -O ./data/tid2013.rar
        7z x ./data/tid2013.rar -o./data/tid2013/
    - name: Run notebooks
      if: ${{ !contains(['examples/Demo_Eigendistortion.ipynb', 'examples/Metamer-Portilla-Simoncelli.ipynb'], matrix.notebook) }}
      run: jupyter execute ${{ matrix.notebook }}.ipynb --kernel_name=python3
    - name: Run notebooks
      if: ${{ matrix.notebook == 'examples/Metamer-Portilla-Simoncelli.ipynb' }}
      # this notebook takes much longer than the rest (if run to completion,
      # ~2hr on a laptop). We use papermill's parameters to reduce the max
      # number of steps for metamer synthesis here (we want to test that each
      # cell runs, but we don't need synthesis to go to completion)
      run: |
        pip install --upgrade --upgrade-strategy eager papermill
        papermill ${{ matrix.notebook }} ${{ matrix.notebook }}_output.ipynb -p short_synth_max_iter 10 -p long_synth_max_iter 10 -p longest_synth_max_iter 10 -k python3 --cwd examples/
    - name: Run notebooks
      if: ${{ matrix.notebook == 'examples/Demo_Eigendistortion.ipynb' }}
      # this notebook takes much longer than the rest (if run to completion,
      # ~1hr on a laptop, more than 5 hours on the Github runners). We use
      # papermill's parameters to reduce the max number of steps for
      # eigendistortion synthesis here (we want to test that each cell runs,
      # but we don't need synthesis to go to completion)
      run: |
        pip install --upgrade --upgrade-strategy eager papermill
        papermill ${{ matrix.notebook }} examples/Demo_Eigendistortion_output.ipynb -p max_steps_frontend 10 -p max_steps_vgg 10 -k python3 --cwd examples/
  tests:
    runs-on: ubuntu-latest
    needs: [get_test_scripts]
    strategy:
      matrix:
        python-version: [3.7, 3.8, 3.9, '3.10']
        test_script: ${{fromJson(needs.get_test_scripts.outputs.script)}}
      fail-fast: false
    name: Run pytest scripts
    steps:
    - uses: actions/checkout@v3
    - name: Install Python 3
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: pip
        cache-dependency-path: setup.py
    - name: Install dependencies
      run: |
        # using the --upgrade and --upgrade-strategy eager flags ensures that
        # pip will always install the latest allowed version of all
        # dependencies, to make sure the cache doesn't go stale
        pip install --upgrade --upgrade-strategy eager .
        pip install --upgrade --upgrade-strategy eager pytest-cov

    - name: Run tests with pytest
      if: ${{ matrix.test_script == 'test_display.py' }}
        # we have two cores on the linux github action runners:
        # https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners
      run: |
        pip install --upgrade --upgrade-strategy eager pytest-xdist
        # for some reason, need to run this in the tests/ dir in order to get
        # coverage to work (I couldn't get an analogous .coveragerc working in
        # the root directory)
        cd tests/ && pytest -n 2 --cov=plenoptic ${{ matrix.test_script }}
        # generate the xml file and move it to root dir for codecov
        coverage xml -o ../coverage.xml
    - name: Run tests with pytest
      if: ${{ matrix.test_script != 'test_display.py' }}
        # only test_display should parallelize across the cores, the others get
        # slowed down by it
      run: |
        # for some reason, need to run this in the tests/ dir in order to get
        # coverage to work (I couldn't get an analogous .coveragerc working in
        # the root directory)
        cd tests/ && pytest --cov=plenoptic ${{ matrix.test_script }}
        # generate the xml file and move it to root dir for codecov
        coverage xml -o ../coverage.xml
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@858dd794fbb81941b6d60b0dca860878cba60fa9 # v3.1.1
  all_tutorials_in_docs:
    runs-on: ubuntu-latest
    name: Check that all tutorial notebooks are included in docs
    needs: [get_notebooks]
    strategy:
      matrix:
        notebook: ${{fromJson(needs.get_notebooks.outputs.notebook)}}
    steps:
    - uses: actions/checkout@v3
    - name: Check for file
      shell: bash
      run: if [[ -z "$(grep ${{ matrix.notebook }} docs/tutorials/*nblink)" ]] ; then
        exit 1; fi
  no_extra_nblinks:
    runs-on: ubuntu-latest
    name: Check that we don't have any extra nblink files
    steps:
    - uses: actions/checkout@v3
    - name: Check same number of nblink and notebooks
      shell: bash
      run: |
        n_nblink=0; for file in docs/tutorials/*nblink; do let "n_nblink+=1"; done;
        n_ipynb=0; for file in examples/*ipynb; do let "n_ipynb+=1"; done;
        if [[ $n_nblink != $n_ipynb ]]; then exit 1; fi;

  check:
    if: always()
    needs:
    - notebooks
    - tests
    runs-on: ubuntu-latest
    steps:
    - name: Decide whether all tests and notebooks succeeded
      uses: re-actors/alls-green@afee1c1eac2a506084c274e9c02c8e0687b48d9e # v1.2.2
      with:
        jobs: ${{ toJSON(needs) }}
